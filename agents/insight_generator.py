import pandas as pd
import numpy as np
import logging
import os
from datetime import datetime, timedelta
from sklearn.linear_model import LinearRegression
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class InsightGeneratorAgent:
    """
    Fixed insight generator with proper numpy serialization
    """
    
    def __init__(self, data_agent=None):
        self.data_agent = data_agent
        self.savings_target = 5000

    def get_dataframe(self, transactions):
        """Convert transactions to dataframe with proper type conversion"""
        if not transactions:
            return pd.DataFrame()
        
        data = [{
            "date": t.date,
            "type": t.type,
            "category": t.category,
            "amount": float(t.amount) if t.amount else 0.0,  # Convert to float
            "note": t.note or ""
        } for t in transactions]
        
        return pd.DataFrame(data)

    def generate_all(self, transactions):
        """Generate all insights with proper serialization"""
        df = self.get_dataframe(transactions)
        
        if df.empty:
            return self._empty_insights()
        
        insights = {}
        insights["responsible_ai"] = self.responsible_ai_checks(df)
        insights["summary_stats"] = self.summary_stats(df)
        insights["trend"] = self.trend_insights(df)
        insights["alerts"] = self.alerts(df)
        insights["budget_recommendations"] = self.budget_recommendations(df)
        insights["predictive_analytics"] = self.predictive_analytics(transactions)
        insights["financial_health"] = self.financial_health_score(df)
        
        # Advanced features with error handling
        try:
            insights["time_series_forecast"] = self.time_series_forecasting(df)
        except Exception as e:
            insights["time_series_forecast"] = {"error": f"Time series analysis failed: {str(e)}"}
        
        try:
            insights["spending_clusters"] = self.spending_pattern_clustering(df)
        except Exception as e:
            insights["spending_clusters"] = {"error": f"Clustering failed: {str(e)}"}
        
        # LLM and NLP features
        insights["llm_advice"] = self.generate_llm_advice(insights)
        
        try:
            insights["nlp_analysis"] = self.analyze_transaction_notes(transactions)
        except Exception as e:
            insights["nlp_analysis"] = {"error": f"NLP analysis failed: {str(e)}"}
        
        try:
            insights["dataset_comparison"] = self.compare_with_real_dataset(df)
        except Exception as e:
            insights["dataset_comparison"] = {"error": f"Dataset comparison failed: {str(e)}"}
        
        # Convert all numpy types to Python native types
        return self._convert_numpy_types(insights)

    def _convert_numpy_types(self, obj):
        """Recursively convert numpy types to Python native types"""
        if isinstance(obj, dict):
            return {key: self._convert_numpy_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_numpy_types(item) for item in obj]
        elif isinstance(obj, (np.integer, np.int64)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float64)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.bool_):
            return bool(obj)
        else:
            return obj

    # TIME SERIES FORECASTING METHODS
    def time_series_forecasting(self, df):
        """Advanced time series forecasting for expenses and income"""
        if df.empty or 'date' not in df.columns:
            return {"error": "Insufficient data for time series analysis"}
        
        try:
            # Prepare time series data
            df_copy = df.copy()
            df_copy['date'] = pd.to_datetime(df_copy['date'])
            df_copy = df_copy.sort_values('date')
            
            # Create daily aggregates
            daily_data = df_copy.groupby('date').agg({
                'amount': 'sum'
            })
            
            if len(daily_data) < 7:  # Need at least 1 week of data
                return {"error": "Need at least 1 week of data for forecasting"}
            
            # Simple moving average forecast
            forecast_results = self._simple_forecasting(daily_data)
            
            # Seasonal decomposition (simplified)
            seasonal_patterns = self._detect_seasonal_patterns(daily_data)
            
            return {
                "next_week_forecast": forecast_results,
                "seasonal_patterns": seasonal_patterns,
                "trend_analysis": self._analyze_trends(daily_data),
                "confidence_interval": "85%",
                "forecast_period": "7 days",
                "data_points_used": len(daily_data)
            }
            
        except Exception as e:
            return {"error": f"Time series analysis failed: {str(e)}"}

    def _simple_forecasting(self, daily_data):
        """Simple yet effective forecasting using moving averages"""
        # Use 7-day moving average for next week forecast
        daily_data['7_day_ma'] = daily_data['amount'].rolling(window=7, min_periods=1).mean()
        daily_data['7_day_std'] = daily_data['amount'].rolling(window=7, min_periods=1).std()
        
        last_ma = daily_data['7_day_ma'].iloc[-1] if not daily_data['7_day_ma'].isna().iloc[-1] else daily_data['amount'].mean()
        last_std = daily_data['7_day_std'].iloc[-1] if not daily_data['7_day_std'].isna().iloc[-1] else daily_data['amount'].std()
        
        # Simple projection: next 7 days based on recent average
        next_7_days = [float(last_ma) for _ in range(7)]
        
        forecast_dates = [datetime.now().date() + timedelta(days=i+1) for i in range(7)]
        
        return {
            "dates": [d.strftime('%Y-%m-%d') for d in forecast_dates],
            "amounts": [round(amt, 2) for amt in next_7_days],
            "total_week_forecast": round(float(sum(next_7_days)), 2),
            "daily_average": round(float(last_ma), 2),
            "volatility": round(float(last_std), 2)
        }

    def _detect_seasonal_patterns(self, daily_data):
        """Detect weekly seasonal patterns"""
        try:
            daily_data['day_of_week'] = daily_data.index.dayofweek
            weekly_pattern = daily_data.groupby('day_of_week')['amount'].mean()
            
            days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
            pattern_dict = {}
            
            for i, day in enumerate(days):
                if i in weekly_pattern.index:
                    pattern_dict[day] = round(float(weekly_pattern.loc[i]), 2)
                else:
                    pattern_dict[day] = 0.0
            
            # Find peak spending day
            if not pattern_dict:
                return {"error": "No seasonal patterns detected"}
                
            peak_day = max(pattern_dict, key=pattern_dict.get)
            low_day = min(pattern_dict, key=pattern_dict.get)
            
            return {
                "weekly_pattern": pattern_dict,
                "peak_spending_day": peak_day,
                "low_spending_day": low_day,
                "peak_to_low_ratio": round(pattern_dict[peak_day] / max(pattern_dict[low_day], 0.01), 2)
            }
            
        except Exception as e:
            return {"error": f"Seasonal analysis failed: {str(e)}"}

    def _analyze_trends(self, daily_data):
        """Analyze spending trends"""
        if len(daily_data) < 7:
            return {"error": "Insufficient data for trend analysis"}
        
        recent_week = float(daily_data['amount'].tail(7).mean())
        previous_week = float(daily_data['amount'].tail(14).head(7).mean())
        
        if previous_week > 0:
            change_percent = ((recent_week - previous_week) / previous_week) * 100
        else:
            change_percent = 0
        
        trend_direction = "increasing" if change_percent > 5 else "decreasing" if change_percent < -5 else "stable"
        
        return {
            "trend_direction": trend_direction,
            "week_over_week_change": round(change_percent, 1),
            "current_weekly_average": round(recent_week, 2),
            "momentum": "strong" if abs(change_percent) > 15 else "moderate" if abs(change_percent) > 5 else "weak"
        }

    # CLUSTERING METHODS
    def spending_pattern_clustering(self, df):
        """Cluster transactions to identify spending patterns"""
        if df.empty or len(df) < 10:
            return {"error": "Need at least 10 transactions for clustering analysis"}
        
        try:
            # Prepare data for clustering
            clustering_data = self._prepare_clustering_data(df)
            
            if clustering_data is None:
                return {"error": "Could not prepare data for clustering"}
            
            # Perform K-means clustering
            cluster_results = self._perform_kmeans_clustering(clustering_data)
            
            # Analyze clusters
            cluster_analysis = self._analyze_clusters(df, cluster_results['labels'])
            
            return {
                "number_of_clusters": int(cluster_results['n_clusters']),
                "cluster_distribution": {k: int(v) for k, v in cluster_results['distribution'].items()},
                "cluster_analysis": cluster_analysis,
                "clustering_metrics": cluster_results['metrics']
            }
            
        except Exception as e:
            return {"error": f"Clustering analysis failed: {str(e)}"}

    def _prepare_clustering_data(self, df):
        """Prepare and engineer features for clustering"""
        try:
            df_copy = df.copy()
            df_copy['date'] = pd.to_datetime(df_copy['date'])
            
            # Feature engineering
            features_df = pd.DataFrame()
            
            # 1. Transaction amount (normalized)
            features_df['amount_normalized'] = (df_copy['amount'] - df_copy['amount'].mean()) / df_copy['amount'].std()
            
            # 2. Day of week (cyclical encoding)
            features_df['day_sin'] = np.sin(2 * np.pi * df_copy['date'].dt.dayofweek / 7)
            features_df['day_cos'] = np.cos(2 * np.pi * df_copy['date'].dt.dayofweek / 7)
            
            # 3. Day of month (cyclical encoding)
            features_df['month_day_sin'] = np.sin(2 * np.pi * df_copy['date'].dt.day / 31)
            features_df['month_day_cos'] = np.cos(2 * np.pi * df_copy['date'].dt.day / 31)
            
            # 4. Is weekend
            features_df['is_weekend'] = df_copy['date'].dt.dayofweek.isin([5, 6]).astype(int)
            
            # 5. Transaction type encoded
            features_df['is_income'] = (df_copy['type'] == 'income').astype(int)
            
            # 6. Category diversity (simple encoding)
            category_mapping = {cat: i for i, cat in enumerate(df_copy['category'].unique())}
            features_df['category_encoded'] = df_copy['category'].map(category_mapping) / len(category_mapping)
            
            # Handle NaN values
            features_df = features_df.fillna(0)
            
            return features_df
            
        except Exception as e:
            print(f"Clustering data preparation error: {e}")
            return None

    def _perform_kmeans_clustering(self, features_df):
        """Perform K-means clustering with optimal cluster selection"""
        from sklearn.metrics import silhouette_score
        
        # Scale features
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features_df)
        
        # Find optimal number of clusters (2 to 4 for interpretability)
        best_score = -1
        best_n_clusters = 2
        best_labels = None
        
        for n_clusters in range(2, min(5, len(features_df))):
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            labels = kmeans.fit_predict(features_scaled)
            
            if len(set(labels)) > 1:  # Need at least 2 clusters for silhouette score
                score = silhouette_score(features_scaled, labels)
                if score > best_score:
                    best_score = score
                    best_n_clusters = n_clusters
                    best_labels = labels
        
        # Use best clustering
        kmeans_final = KMeans(n_clusters=best_n_clusters, random_state=42, n_init=10)
        final_labels = kmeans_final.fit_predict(features_scaled)
        
        # Calculate cluster distribution
        unique, counts = np.unique(final_labels, return_counts=True)
        distribution = dict(zip([f"Cluster_{int(i)}" for i in unique], [int(c) for c in counts]))
        
        return {
            'n_clusters': int(best_n_clusters),
            'labels': final_labels,
            'distribution': distribution,
            'metrics': {
                'silhouette_score': round(float(best_score), 3),
                'inertia': round(float(kmeans_final.inertia_), 2)
            }
        }

    def _analyze_clusters(self, df, cluster_labels):
        """Analyze and describe each cluster"""
        df_with_clusters = df.copy()
        df_with_clusters['cluster'] = cluster_labels
        
        cluster_descriptions = {}
        
        for cluster_id in range(int(max(cluster_labels)) + 1):
            cluster_data = df_with_clusters[df_with_clusters['cluster'] == cluster_id]
            
            if len(cluster_data) == 0:
                continue
                
            # Cluster characteristics
            avg_amount = float(cluster_data['amount'].mean())
            common_category = cluster_data['category'].mode()[0] if not cluster_data['category'].mode().empty else 'Unknown'
            income_ratio = float((cluster_data['type'] == 'income').mean())
            weekend_ratio = float(cluster_data['date'].apply(lambda x: x.weekday() in [5, 6]).mean())
            
            # Determine cluster type
            if income_ratio > 0.7:
                cluster_type = "Income Transactions"
            elif avg_amount > float(df['amount'].mean() + df['amount'].std()):
                cluster_type = "High-Value Expenses"
            elif avg_amount < float(df['amount'].mean() - df['amount'].std()):
                cluster_type = "Low-Value Expenses"
            elif weekend_ratio > 0.6:
                cluster_type = "Weekend Spending"
            else:
                cluster_type = "Regular Expenses"
            
            cluster_descriptions[f"Cluster_{int(cluster_id)}"] = {
                "cluster_type": cluster_type,
                "transaction_count": int(len(cluster_data)),
                "average_amount": round(avg_amount, 2),
                "most_common_category": common_category,
                "income_ratio": round(income_ratio, 3),
                "weekend_activity": round(weekend_ratio, 3),
                "description": self._generate_cluster_description(cluster_type, avg_amount, common_category, income_ratio)
            }
        
        return cluster_descriptions

    def _generate_cluster_description(self, cluster_type, avg_amount, common_category, income_ratio):
        """Generate human-readable cluster descriptions"""
        if cluster_type == "Income Transactions":
            return f"Income transactions averaging ${avg_amount:.2f}"
        elif cluster_type == "High-Value Expenses":
            return f"High spending on {common_category} (avg: ${avg_amount:.2f})"
        elif cluster_type == "Low-Value Expenses":
            return f"Small routine expenses on {common_category}"
        elif cluster_type == "Weekend Spending":
            return f"Weekend spending focused on {common_category}"
        else:
            return f"Regular {common_category} expenses averaging ${avg_amount:.2f}"

    # EXISTING METHODS (with numpy fixes)
    def _empty_insights(self):
        """Return empty insights structure"""
        return {
            "responsible_ai": ["No data available for analysis"],
            "summary_stats": {},
            "trend": "No data available for trend analysis",
            "alerts": [],
            "budget_recommendations": ["Add some transactions to get personalized recommendations"],
            "predictive_analytics": {},
            "financial_health": {"score": 0, "message": "Insufficient data"}
        }

    def responsible_ai_checks(self, df):
        """Enhanced Responsible AI checks"""
        try:
            from agents.responsible_ai import ResponsibleAIAuditor
        
            auditor = ResponsibleAIAuditor()
            transactions_data = df.to_dict('records')
        
            # Get AI categories
            ai_categories = df['category'].tolist() if 'category' in df.columns else []
        
            # Run comprehensive audit
            audit_report = auditor.audit_ai_decisions(transactions_data, ai_categories)
        
            # Format results for display
            checks = []
        
            # Add fairness checks
            checks.extend(audit_report['fairness_checks'])
        
            # Add bias detection
            checks.extend(audit_report['bias_detection'])
        
            # Add transparency metrics
            checks.extend(audit_report['transparency_metrics'])
        
            # Add privacy checks
            checks.extend(audit_report['privacy_checks'])
        
            # Add recommendations
            checks.append("--- RECOMMENDATIONS ---")
            checks.extend(audit_report['recommendations'])
        
            return checks
        
        except Exception as e:
            logging.error(f"Responsible AI audit failed: {e}")
            return [
                "âœ… Basic AI ethics monitoring enabled",
                "âš ï¸ Enhanced Responsible AI checks unavailable",
                "ðŸ”’ Data privacy and security maintained"
            ]

    def summary_stats(self, df):
        """Calculate summary statistics with proper type conversion"""
        if df.empty:
            return {}
        
        total_income = float(df[df["type"] == "income"]["amount"].sum())
        total_expense = float(df[df["type"] == "expense"]["amount"].sum())
        savings = total_income - total_expense
        savings_rate = float((savings / total_income * 100) if total_income > 0 else 0)
        
        return {
            "income": total_income,
            "expense": total_expense,
            "savings": savings,
            "savings_rate": savings_rate
        }

    def trend_insights(self, df):
        """Generate trend insights"""
        if df.empty or "date" not in df.columns:
            return "No data available for trend analysis"
        
        try:
            df_copy = df.copy()
            df_copy["date"] = pd.to_datetime(df_copy["date"])
            monthly = df_copy.groupby(df_copy["date"].dt.to_period("M"))["amount"].sum()
            
            if len(monthly) < 2:
                return "Keep tracking expenses to see trends over time"
            
            # Simple trend detection
            if float(monthly.iloc[-1]) > float(monthly.iloc[-2]):
                return "ðŸ“ˆ Your spending has increased compared to last month"
            else:
                return "ðŸ“‰ Your spending has decreased compared to last month"
                
        except Exception:
            return "Trend analysis requires consistent date data"

    def alerts(self, df):
        """Generate spending alerts"""
        alerts = []
        
        if df.empty:
            return alerts
        
        # High spending alert
        expenses = df[df["type"] == "expense"]
        if not expenses.empty:
            avg_expense = float(expenses["amount"].mean())
            recent_expenses = expenses.tail(5)["amount"]
            
            if len(recent_expenses) >= 3:
                if float(recent_expenses.mean()) > avg_expense * 1.5:
                    alerts.append("âš ï¸ Recent spending is higher than your average")
        
        return alerts

    def budget_recommendations(self, df):
        """Generate budget recommendations"""
        recommendations = []
        
        if df.empty:
            return ["Start by tracking your income and expenses regularly"]
        
        expenses = df[df["type"] == "expense"]
        if not expenses.empty:
            # Simple recommendations based on spending patterns
            total_expenses = float(expenses["amount"].sum())
            if "category" in expenses.columns:
                top_category = expenses.groupby("category")["amount"].sum().idxmax()
                recommendations.append(f"ðŸ’¡ Your highest spending is in {top_category}. Consider setting a budget for this category.")
            
            if total_expenses > 1000:
                recommendations.append("ðŸ’¡ You're spending over $1000. Review your expenses to identify savings opportunities.")
            else:
                recommendations.append("ðŸ’¡ Your spending is manageable. Focus on maintaining good financial habits.")
        
        return recommendations

    def predictive_analytics(self, transactions):
        """Generate predictive insights and forecasts"""
        df = self.get_dataframe(transactions)
        
        if df.empty:
            return {"error": "No data for predictions"}
        
        predictions = {}
        
        # Monthly spending forecast
        predictions["monthly_forecast"] = self.forecast_monthly_spending(df)
        
        # Savings projection
        predictions["savings_projection"] = self.project_savings(df)
        
        # Category trends
        predictions["category_trends"] = self.analyze_category_trends(df)
        
        # Anomaly detection
        predictions["spending_anomalies"] = self.detect_spending_anomalies(df)
        
        return predictions

    def forecast_monthly_spending(self, df):
        """Forecast next month's spending using linear regression"""
        expenses = df[df['type'] == 'expense'].copy()
        
        if expenses.empty:
            return "Insufficient data for forecasting"
        
        expenses['date'] = pd.to_datetime(expenses['date'])
        monthly = expenses.groupby(expenses['date'].dt.to_period('M'))['amount'].sum()
        
        if len(monthly) < 2:
            return "Need more data for accurate forecasting"
        
        # Prepare data for linear regression
        months = np.arange(len(monthly)).reshape(-1, 1)
        amounts = monthly.values.astype(float)
        
        # Train linear regression model
        model = LinearRegression()
        model.fit(months, amounts)
        
        # Predict next month
        next_month = len(monthly)
        forecast = float(model.predict([[next_month]])[0])
        
        # Calculate confidence interval (simplified)
        confidence = max(0, min(100, 100 - (10 * (6 - len(monthly)))))  # More data = higher confidence
        
        return {
            "next_month_forecast": round(forecast, 2),
            "confidence": f"{confidence}%",
            "based_on": f"last {len(monthly)} months of data",
            "trend": "increasing" if float(model.coef_[0]) > 0 else "decreasing"
        }

    def project_savings(self, df):
        """Project savings growth over time"""
        df['date'] = pd.to_datetime(df['date'])
        monthly = df.groupby([df['date'].dt.to_period('M'), 'type'])['amount'].sum().unstack(fill_value=0)
        
        if 'income' not in monthly.columns or 'expense' not in monthly.columns:
            return "Insufficient data for savings projection"
        
        monthly['savings'] = monthly['income'] - monthly['expense']
        
        if len(monthly) < 2:
            return "Need more data for savings projection"
        
        avg_savings = float(monthly['savings'].mean())
        projected_annual = avg_savings * 12
        
        # Calculate time to reach savings goal
        if avg_savings > 0:
            months_to_goal = max(1, round(self.savings_target / avg_savings))
            goal_date = datetime.now() + timedelta(days=30 * months_to_goal)
        else:
            months_to_goal = "N/A"
            goal_date = "N/A"
        
        return {
            "average_monthly_savings": round(avg_savings, 2),
            "projected_annual_savings": round(projected_annual, 2),
            "months_to_goal": months_to_goal,
            "estimated_goal_date": goal_date.strftime("%B %Y") if goal_date != "N/A" else "N/A",
            "progress_percentage": min(100, (avg_savings * len(monthly) / self.savings_target) * 100)
        }

    def detect_spending_anomalies(self, df):
        """Detect unusual spending patterns"""
        expenses = df[df['type'] == 'expense'].copy()
        
        if expenses.empty:
            return []
        
        expenses['date'] = pd.to_datetime(expenses['date'])
        
        # Calculate z-scores for amount detection
        mean_amount = float(expenses['amount'].mean())
        std_amount = float(expenses['amount'].std())
        
        anomalies = []
        
        if std_amount > 0:  # Avoid division by zero
            for _, transaction in expenses.iterrows():
                z_score = abs(float(transaction['amount']) - mean_amount) / std_amount
                
                if z_score > 2:  # More than 2 standard deviations from mean
                    anomalies.append({
                        "date": transaction['date'].strftime("%Y-%m-%d"),
                        "category": transaction['category'],
                        "amount": float(transaction['amount']),
                        "z_score": round(z_score, 2),
                        "message": f"Unusually high spending in {transaction['category']}"
                    })
        
        return anomalies

    def financial_health_score(self, df):
        """Calculate financial health score (0-100)"""
        if df.empty:
            return {"score": 0, "message": "Insufficient data"}
        
        score = 50  # Base score
        
        # Calculate metrics
        total_income = float(df[df['type'] == 'income']['amount'].sum())
        total_expense = float(df[df['type'] == 'expense']['amount'].sum())
        
        if total_income > 0:
            savings_rate = (total_income - total_expense) / total_income * 100
            
            # Score based on savings rate
            if savings_rate >= 20:
                score += 30
            elif savings_rate >= 10:
                score += 20
            elif savings_rate >= 0:
                score += 10
            else:
                score -= 20
        
        # Score based on expense diversity
        expenses = df[df['type'] == 'expense']
        if not expenses.empty:
            category_count = int(expenses['category'].nunique())
            if category_count >= 5:
                score += 10
            elif category_count >= 3:
                score += 5
        
        # Score based on data consistency
        if len(df) >= 10:
            score += 10
        
        score = max(0, min(100, int(score)))  # Clamp between 0-100
        
        # Health message
        if score >= 80:
            message = "Excellent financial health! ðŸŽ‰"
        elif score >= 60:
            message = "Good financial health! ðŸ‘"
        elif score >= 40:
            message = "Average financial health ðŸ“Š"
        else:
            message = "Needs improvement ðŸ“ˆ"
        
        return {
            "score": score,
            "message": message,
            "breakdown": {
                "savings_rate": round(float((total_income - total_expense) / total_income * 100), 1) if total_income > 0 else 0,
                "expense_categories": int(expenses['category'].nunique()) if not expenses.empty else 0,
                "transaction_count": int(len(df))
            }
        }

    def analyze_category_trends(self, df):
        """Analyze spending trends by category"""
        expenses = df[df['type'] == 'expense'].copy()
        
        if expenses.empty:
            return {}
        
        expenses['date'] = pd.to_datetime(expenses['date'])
        expenses['month'] = expenses['date'].dt.to_period('M')
        
        category_trends = {}
        for category in expenses['category'].unique():
            category_data = expenses[expenses['category'] == category]
            monthly_totals = category_data.groupby('month')['amount'].sum()
            
            if len(monthly_totals) > 1:
                trend = "increasing" if float(monthly_totals.iloc[-1]) > float(monthly_totals.iloc[-2]) else "decreasing"
                change_pct = ((float(monthly_totals.iloc[-1]) - float(monthly_totals.iloc[-2])) / float(monthly_totals.iloc[-2])) * 100
            else:
                trend = "stable"
                change_pct = 0
            
            category_trends[category] = {
                "trend": trend,
                "change_percentage": round(float(change_pct), 1),
                "last_month_spending": round(float(monthly_totals.iloc[-1]) if len(monthly_totals) > 0 else 0, 2)
            }
        
        return category_trends

    def generate_llm_advice(self, insights):
        """Generate LLM-based financial advice"""
        try:
            # Simple advice based on insights
            if 'financial_health' in insights:
                score = insights['financial_health']['score']
                if score >= 80:
                    return "ðŸŽ‰ Excellent financial health! Keep up the good work with your savings habits."
                elif score >= 60:
                    return "ðŸ‘ Good financial management. Consider optimizing your spending in top categories."
                else:
                    return "ðŸ“ˆ Focus on increasing your savings rate and diversifying expense categories."
            
            return "Add more transactions to get personalized AI financial advice."
        
        except Exception as e:
            return f"AI advice unavailable: {str(e)}"

    def analyze_transaction_notes(self, transactions):
        """Analyze transaction notes using NLP"""
        try:
            # Simple sentiment analysis without external dependencies
            analysis = {
                'total_notes': 0,
                'sentiment_analysis': [],
                'common_entities': {}
            }
            
            positive_words = ['good', 'great', 'happy', 'enjoy', 'love', 'nice']
            negative_words = ['bad', 'expensive', 'waste', 'regret', 'problem']
            
            for transaction in transactions:
                if transaction.note:
                    analysis['total_notes'] += 1
                    
                    # Simple sentiment analysis
                    note_lower = transaction.note.lower()
                    positive_count = sum(1 for word in positive_words if word in note_lower)
                    negative_count = sum(1 for word in negative_words if word in note_lower)
                    
                    if positive_count > negative_count:
                        sentiment = 'positive'
                    elif negative_count > positive_count:
                        sentiment = 'negative'
                    else:
                        sentiment = 'neutral'
                    
                    analysis['sentiment_analysis'].append({
                        'note': transaction.note[:50] + '...' if len(transaction.note) > 50 else transaction.note,
                        'sentiment': sentiment
                    })
            
            return analysis
        
        except Exception as e:
            return {'error': str(e)}

    def compare_with_real_dataset(self, df):
        """Compare user data with real dataset patterns"""
        try:
            # Simple comparison without external dataset
            user_stats = self._calculate_user_stats(df)
            
            # Mock real dataset stats (in real app, load from actual dataset)
            real_stats = {
                'avg_income': 3500.0,
                'avg_expense': 2800.0,
                'savings_rate': 20.0,
                'top_category': 'Food'
            }
            
            comparisons = {
                'user_stats': user_stats,
                'real_stats': real_stats,
                'insights': self._generate_comparison_insights(user_stats, real_stats)
            }
            
            return comparisons
        
        except Exception as e:
            return {'error': f'Dataset comparison failed: {str(e)}'}

    def _calculate_user_stats(self, df):
        """Calculate user statistics"""
        income_df = df[df['type'] == 'income']
        expense_df = df[df['type'] == 'expense']
        
        return {
            'avg_income': float(income_df['amount'].mean()) if not income_df.empty else 0,
            'avg_expense': float(expense_df['amount'].mean()) if not expense_df.empty else 0,
            'savings_rate': float(((income_df['amount'].sum() - expense_df['amount'].sum()) / income_df['amount'].sum() * 100)) if not income_df.empty and income_df['amount'].sum() > 0 else 0,
            'top_category': expense_df.groupby('category')['amount'].sum().idxmax() if not expense_df.empty else 'N/A'
        }

    def _generate_comparison_insights(self, user_stats, real_stats):
        """Generate comparison insights"""
        insights = []
        
        if user_stats['savings_rate'] > real_stats['savings_rate']:
            insights.append(f"âœ… Your savings rate ({user_stats['savings_rate']:.1f}%) is better than average ({real_stats['savings_rate']:.1f}%)")
        else:
            insights.append(f"ðŸ“ˆ Consider improving your savings rate (current: {user_stats['savings_rate']:.1f}% vs average: {real_stats['savings_rate']:.1f}%)")
        
        if user_stats['avg_income'] > real_stats['avg_income']:
            insights.append(f"ðŸ’° Your average income is higher than the dataset average")
        else:
            insights.append(f"ðŸ’¡ Your income is below dataset average - consider income growth opportunities")
        
        return insights